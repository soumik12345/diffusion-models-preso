<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/night.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
		<style>
			.circular_image {
				width: 70%;
				height: 70%;
				border-radius: 50%;
				overflow: hidden;
				display:inline-block;
				vertical-align:middle;
			  }
			  .circular_image img{
				width:100%;
			  }

			  #left {
				left:-8.33%;
				text-align: left;
				float: left;
				width:50%;
				z-index:-10;
			  }
			  
			  #right {
				left:31.25%;
				top: 75px;
				float: right;
				text-align: right;
				z-index:-10;
				width:50%;
			  }
			  .container {
				display: flex;
			  }

			  .col {
				flex: 1;
			  }
		</style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<!-- Slide 1 -->
				<section data-markdown>
					<textarea data-template>
					  ## A Landscape of [Diffusion Models]() in [2024]()

					  Presented by [Soumik Rakshit](https://geekyrakshit.dev/)
					</textarea>
				</section>
				<!-- Slide 2 -->
				<section data-markdown>
					<textarea data-template>
						<div id="left">
							<p>
								Follow along at <br>
								<p style="padding-top: 5%;">
									<a href="bit.ly/diffusion-2024">bit.ly/diffusion-2024</a>
								</p>
							</p>
						</div>
						<div id="right">
							<img src="./examples/assets/qr1.png" alt="">
						</div>
					</textarea>
				</section>
				<!-- Slide 3 -->
				<section data-markdown>
					<textarea data-template>
						<div id="left">
							<img class="circular_image" src="https://geekyrakshit.dev/assets/soumik_rakshit.png" alt="">
						</div>
						<div id="right">
							<p style="text-align: left; font-size: 80%; padding-bottom: 5%;">$>whoami</p>
							<p style="text-align: left; font-size: 50%; line-height: 175%;">
								üëã Building tools for ML using ML <a href="https://wandb.ai/site">@WandB</a>.<br>
								üëã Google Developer Expert in ML (JAX).<br>
								üëã Former ML Research @IBM and @Ignitarium.<br>
								üëã I build MLOps pipelines for open-source repositories (Keras, ü§ó Diffusers, MonAI, etc.)<br>
								üëã I am actively working on <a href="https://github.com/soumik12345/wandb-addons"></a>WandB-Addons</a>.<br>
								üëã Playing üéª between work; MineCraft and Elden Ring after work.<br>
								üëã More about myself at <a href="https://geekyrakshit.dev/">geekyrakshit.dev</a>
							</p>
						</div>
					</textarea>
				</section>
				<!-- Slide 4 -->
				<section>
					<section>
						Diffusion Models are a new family of generative models have that have taken the world by storm üå™Ô∏è
					</section>
					<section>
						The idea was proposed by the paper
						<a href="https://arxiv.org/pdf/2006.11239.pdf">Denoising Diffusion Probabilistic Models</a>
						in 2021, and the world was never the same again.
					</section>
					<section>
						In this presentation, first we will explore some image generation techniques pre-dating diffusion models.
					</section>
					<section>
						Next we will breifly explore the basic idea behind diffusion models.
					</section>
					<section>
						After that, we will look at a simple and flexible pipeline for training diffusion models for <a href="https://geekyrakshit.dev/diffusion-models-preso#/3/2">unconditional image generation</a>
					</section>
					<section>
						Finally, we will look at some of the recent advancements in diffusion models and their applications.
					</section>
				</section>
				<!-- Slide 5 -->
				<section data-markdown>
					<textarea data-template>
						## Stone Age of Image Generation
  
						[The era before the dawn of Diffusion]()
					  </textarea>
				</section>
				<!-- Slide 6 -->
				<section>
					<section>
						<p style="font-size: 150%; padding-bottom: 10%;">
							Let's talk about
							<a href="#/5"><strong>AutoEncoders</strong></a>
						</p>
					</section>
					<section>
						<img src="./examples/assets/autoencoder1.png">
						Let's say we want to transfer this image of a dog over a network.
					</section>
					<section>
						Long image data isn't compact and may take a long time to transfer over a network.
					</section>
					<section>
						So... how do we overcome this network bandwidth bottleneck?
					</section>
					<section>
						<img src="./examples/assets/autoencoder2.png">
						<a href="#/5/4">The Plan:</a>
						We can compress the image data at the source.
						Then send the compressed image over the network.
						Finally reconstruct the original image from the compressed one at the destination.
					</section>
					<section>
						<p style="font-size: 150%; padding-bottom: 10%;">
							A solid plan, right?
						</p>
					</section>
					<section>The question is how do we compress the image and then reconstruct it?</section>
					<section>
						How do we <a href="#5/7">teach a neural network</a> compress the image and then reconstruct it?
					</section>
					<section>
						We are surrounded by a lot of very high-dimensional data.
						\[\begin{aligned}
						x \in \mathbb{R}^{D}
						\end{aligned} \]
					</section>
					<section>
						<a href="#5/8">AutoEncoders</a> are a type of Unsupervised Neural Network that can learn a simple representation of the data.
					</section>
					<section>
						<img src="./examples/assets/autoencoder4.png" alt="">
					</section>
					<section>
						The objective of an Autoencoder is to learn a reconstruction loss $$ min Loss(x, r) $$ for a given set of high-dimensional data $$ x \in \mathbb{R}^{D} $$
					</section>
					<section>
						AutoEncoders are easy to train, but they don't always produce good results.
					</section>
					<section>
						Moreover, you can't generate new data from them.
					</section>
					<section>
						<div class="container">
							<div class="col">
								If you want to learn more about AutoEncoders, you can check out this excellent video üëâ
							</div>
							<div class="col">
								<iframe width="560" height="315" src="https://www.youtube.com/embed/7mRfwaGGAPg?si=e068hmAARY2fgG5B" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
							</div>
						</div>
					</section>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
			Reveal.initialize({ plugins: [ RevealMath.KaTeX ] });
		</script>
	</body>
</html>
